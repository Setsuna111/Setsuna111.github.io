<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">

<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="流生成模型基本框架之一-GLOW及部分应用">
<meta property="og:type" content="article">
<meta property="og:title" content="Flow-based Generative Models">
<meta property="og:url" content="http://example.com/2022/01/30/Flow-based-Generative-Model/index.html">
<meta property="og:site_name" content="Setsuna&#39;s Park">
<meta property="og:description" content="流生成模型基本框架之一-GLOW及部分应用">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-01-30T13:58:48.000Z">
<meta property="article:modified_time" content="2022-02-25T15:45:36.881Z">
<meta property="article:author" content="Setsuna F">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Journal Club">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/01/30/Flow-based-Generative-Model/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Flow-based Generative Models | Setsuna's Park</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
    <a target="_blank" rel="noopener" href="https://github.com/Setsuna111" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style></a>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Setsuna's Park</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="fa fa-download fa-fw"></i>资源</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/01/30/Flow-based-Generative-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/Setsuna.gif">
      <meta itemprop="name" content="Setsuna F">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Setsuna's Park">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Flow-based Generative Models
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-01-30 21:58:48" itemprop="dateCreated datePublished" datetime="2022-01-30T21:58:48+08:00">2022-01-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-02-25 23:45:36" itemprop="dateModified" datetime="2022-02-25T23:45:36+08:00">2022-02-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning-Model/" itemprop="url" rel="index"><span itemprop="name">Deep Learning Model</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/01/30/Flow-based-Generative-Model/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/01/30/Flow-based-Generative-Model/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description">流生成模型基本框架之一-GLOW及部分应用</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="0-引言"><a href="#0-引言" class="headerlink" title="0. 引言"></a>0. 引言</h1><p>借第一次Journal Club的机会，系统回顾一下流模型相关知识</p>
<h1 id="1-GLOW：Glow-Generative-Flow-with-Invertible-1×1-Convolutions"><a href="#1-GLOW：Glow-Generative-Flow-with-Invertible-1×1-Convolutions" class="headerlink" title="1. GLOW：Glow: Generative Flow with Invertible 1×1 Convolutions"></a>1. GLOW：Glow: Generative Flow with Invertible 1×1 Convolutions</h1><h2 id="1-1-流生成模型简介-背景"><a href="#1-1-流生成模型简介-背景" class="headerlink" title="1.1 流生成模型简介-背景"></a>1.1 流生成模型简介-背景</h2><h3 id="1-1-1-负对数似然优化目标"><a href="#1-1-1-负对数似然优化目标" class="headerlink" title="1.1.1 负对数似然优化目标"></a>1.1.1 负对数似然优化目标</h3><ol>
<li>似然与概率有何不同<br>概率（probability）指一个事件发生的可能性，似然（likelihood）指在参数可变情况下计算出的概率。<br><strong>似然可以用来估计概率公式中未知的参数，即将概率公式的一些参数变量化后表示</strong>，【因此 作为损失函数时才叫做似然，因为是通过似然去拟合概率嘛】，关系如下：$$L(\theta|x)=p_\theta(x)$$相当于是给定样本集x下的条件概率。</li>
<li>负对数似然的意义<br>使用样本来进行估计概率的时候，单看一个样本，其发生的概率就是1，所以使用当前参数计算这个样本发生的概率即可，注意需要考虑样本数据集$D$中的每一个样本点，所以最后表示成连乘的形式$$L(D)=\prod_{x\in D}P_\theta(x)$$<br>所以取对数避免连乘操作溢出（某一值特别小或者等于0的时候会带来过分的影响），同时取-用于loss（梯度下降优化一个负的数不就是求最大似然的过程嘛），综合二者可表示为NLL_Loss</li>
<li>为何离散和连续变量形式不同？<br>对连续函数来说，某一具体值的发生概率一定是0，所以考虑在一定区间内进行考察~</li>
</ol>
<h3 id="1-1-2-流生成模型基本框架"><a href="#1-1-2-流生成模型基本框架" class="headerlink" title="1.1.2 流生成模型基本框架"></a>1.1.2 流生成模型基本框架</h3><p>   生成过程可由以下两式表示$$z\sim p_\theta (z)$$ $$x = g_\theta(z)$$<br>   其中$z$为高维隐变量，生成过程即为从规范化的隐变量分布（一般为高斯分布）采样，并通过可逆变换$g$生成复杂分布x<br>2. 所谓可逆变换，即上述生成分布x的过程可以表示为由x推断隐变量的过程：$z = f_\theta(x)=g_\theta ^{-1}(x)$，也称这种变换为双边映射。当连续的多层变换组合到一起，就形成了“流”<br>3. 根据概率分布变换公式，可以得到$$logp(x)=logp(z)+\sum_{i=1}^{K}log|det(dh_i/dh_{i-1})|$$<br>   为了使雅各比行列式好算，需要构造具有下三角矩阵的变换，并且满足可逆要求</p>
<ol start="4">
<li><p><strong>流生成模型的loss究竟是什么？</strong></p>
<p>很简单，也很巧妙，就是对x的似然函数进行计算，因为样本就是x，每一个样本下的发生概率都是1，去计算他的发生概率并连乘就可以了<br>在计算的过程中因为能够将p(x)精确表示才可以这样，这就是flow厉害的地方，使用x计算出z后，代入z的分布函数，就能精确计算出p(x)的值！！！<br><strong>注意</strong>，不可以将它只看做一个由x生成z的网络进行训练，训练的目标必须是生成x，但计算流向却是由z到x。<br>原因：如果只考虑z的似然函数（即只当成生成z的过程）会使z趋于0，因为此时概率最大；那这样去计算z和正态分布的相似程度，用KL散度去衡量不就行了吗？是可以，但这是VAE。。。并没有利用flow精确计算出x的分布！！<br><strong>以下为一次错误的思考，其中理解二应该是差不多正确的，且交叉熵和KL散度确实可以用来代替负对数似然，但注意对象也是面向x和样本的确定值！！！！！</strong>【有没有一种可能，法一也是正确的，但计算完z的似然后需要把雅各比行列式这一项也加上】<br><strong>错</strong><br>是负对数似然，但是要搞清楚训练的是什么方向，以及是和谁的负对数似然<br>可参照glow源码的_f_loss部分，当然这里有一个更熟悉的<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/270357012">pytorch版本的nice源码</a><br>可选用的将隐变量z规范化的分布：高斯分布或logistics分布。<br>实例化模型后其输出的负对数似然即为loss，<strong>但怎样理解似然函数？？？和什么似然？？</strong><br>（0）先仔细理解似然函数和概率的差别<br>（0）训练过程可以看做训练了一个生成模型g(z)即可，等等这样在表示loss上有点不好理解？也可以这样理解，见下面补充<br>（1）我们现在有训练集，假如100个样本。这100个样本具有未知的分布$x\sim p_0(x)$，训练过程为从x到z，则由x的真实分布样本生成了z的一个分布样本，这个是与模型参数相关的，记作$z\sim p(z)$。注意这个z是没有规律的<br>（2）训练优化目标：就是使用该模型计算出的$x\sim p(x)$的负对数似然，既然是似然那一定有从样本得出的可以去比较的分布，这个分布就是$p_0(x)$<br>（3）那么，怎么表示使用该模型计算出的$x\sim p(x)$呢？使用概率函数变量替换公式，p(x)可以由p(z)和一系列雅各比行列式表示<br>（4）注意表示后的含义是：行列式就是标量，相加即可，但$p(z)$则表示要求该模型下z的分布的负对数似然，他和谁去比较呢？即先验设置好的分布$p_0(z)$<br>（5）怎么去计算负对数似然：使用$p(z)$和$p_0(z)$的KL散度或cross_entropy<br>KL散度实际上有两项，但优化他刚好和优化负对数似然一样了，具体可以参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/273246971">生成模型大观-极大似然法</a><br>那么交叉熵呢？KL散度和交叉熵在真实分布不变的时候（流模型为z的先验分布）完全可以相互替换。。。可以看这一篇<a target="_blank" rel="noopener" href="https://blog.csdn.net/yinyu19950811/article/details/90706188">文章</a>。看里面写KL散度多减一项，实际上如果那一项不减就是cross_entropy，就是负对数似然要的东西（是的！这样就更直观理解了，优化目标就是减小求得的分布和先验分布之间的距离！）<br>关系？理解这个式子，可参考<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/268171298">知乎</a>$$CrossEntropy(y_{true},y_{pred})=-log(L)=-\sum_{i=1}^Ky_{true}(i)log(y_{pred}(i))$$<br>原因：<strong>见原文章，看明白多分类问题的分类函数就明白了一般（实际上就是二点分布的推广。。）</strong>！！！！！<br>另一半：就是把指数看成带参数模型输出的一组值。。。就是概率转化为似然的过程！！！！！！！！！  </p>
<p><strong>补充理解</strong>：把训练过程看做g（z）的生成过程的训练，对高斯分布能把似然函数写出来的！！！见<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/270357012">1</a>，这样不用计算交叉熵了，直接套入公式。。。。<br>补充理解和上面（1）-（5）如何统一？？本身就是统一的。。。第一种思路只能转化到z的分布再去优化，看x的分布不可能看得出来。第二种存疑，那个知乎为什么那么简单就写出了似然函数？？？？</p>
</li>
<li><p>最后可能加一个scaling层，nice之类的加了，就相当于多一项雅各比行列式即可</p>
</li>
</ol>
<h2 id="1-2-GLOW框架"><a href="#1-2-GLOW框架" class="headerlink" title="1.2 GLOW框架"></a>1.2 GLOW框架</h2><h3 id="1-2-0-从两个角度去理解：单个flow层内每一模块的作用-整体的多尺度框架"><a href="#1-2-0-从两个角度去理解：单个flow层内每一模块的作用-整体的多尺度框架" class="headerlink" title="1.2.0 从两个角度去理解：单个flow层内每一模块的作用+整体的多尺度框架"></a>1.2.0 从两个角度去理解：单个flow层内每一模块的作用+整体的多尺度框架</h3><p>###1.2.1 Actnorm层：对每一个Activation进行normalization<br>与一般的batch normalization有何不同？是否满足可逆和易于计算？</p>
<ol>
<li>回顾一下一般的BN做了什么<br>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/168791054">文章1</a>,<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/38102762">文章2</a>,<a target="_blank" rel="noopener" href="https://blog.csdn.net/hjimce/article/details/50866313">文章3</a><br>深度学习需要在特定的输入分布上学习一个模型，并在训练集上具有泛化能力，所以输入分布的一致性很重要<br>但是受限于计算资源，只能每次从训练数据集中取一个batch进行输入训练。输入<strong>batch之间</strong>可能会具有分布偏差，且经过网络层后数据分布也会改变，这种现象叫做<strong>Internal Covariate Shift</strong><br><strong>解决方法</strong>：对这个batch根据其方差和均值进行归一化，随后进行scale and shift，变换为与想要的分布一致的分布！！！后者的参数可学，但是对所有batch都是一样的参数<br>补充：如果只有归一化过程，也叫作“白化”，即变成白噪声的预处理方法</li>
<li>scale and shift与激活函数<br>二者概念不同，注意scale and shift确实是可学习的参数，他存在的意义是让BN可以将分布拟合为均值0方差1的规范化分布，也可以不改变原输入的分布。这样在层与层之间传递参数时，可以保留上一层学习到的特征分布！（或者这样理解：如果未标准化的输入反而是最优输入，标准化后不就寄了）<br>BN在何处使用？用在每一层输入开始的时候，使得当前层的输入分布相对规范化</li>
<li>CNN中如何做BN<br>在各个通道维度上做BN。<br>batch_size为N，维度数量为C，长宽为H，W，则每一层的BN是对NxWxH个数据进行求解</li>
<li>为什么要引入Actnorm<br>activation normalizaton，理解为针对每一个activation规范化，而非二者相加吧。。。。就和google最初BN论文中对单个神经元初始化的过程一样<br>那么叫这个名字什么含义？和BN一样首先规范化然后scale and bias，只不过受限于大型图像，训练的batch size往往为1，此时退化为单个神经元处理单层，所以一般的BN也变换为对对一个channel上feature map规范化了。</li>
<li>Actorm怎么做的<br>规范化如上，后续进行scale and bias的时候初始化二者为初始batch的均值和方差（<strong>不对！</strong>）<br>原文的表述稍有不同？归一化的参数设定为<strong>针对初始输入的mini-batch，使得actnorm层后的神经元的输入在每一通道上均值为0，方差为1</strong><br>这tm能是一个意思吗？？？？<strong>所以看代码得到就应该是0初始化！</strong> 这才能满足文章的要求，苏剑林写的文有bug。</li>
</ol>
<h3 id="1-2-2-可逆1x1卷积"><a href="#1-2-2-可逆1x1卷积" class="headerlink" title="1.2.2 可逆1x1卷积"></a>1.2.2 可逆1x1卷积</h3><ol>
<li><p>操作：将按channel维度的随机打乱使用可学习的变换来替代。</p>
</li>
<li><p>为何要叫他1x1卷积？？？<br>假设要进行重新排列的某个中间变量维度为$h\times w \times c$，$c$为通道数。<br>则如果使用一个矩阵W对特征图按通道进行重新排列，W的维度应该为$c \times c$，在计算雅各比行列式的时候，该变换的雅克比行列式就为W的行列式<br>方法一：直接计算行列式，时间复杂度为$O(c^3)$（雀食 三阶行列式就是三个a相乘嘛，注意实际操作的时候维度不只是3，应该考虑pixel的数量）</p>
<p><strong>注意这里为什么可以等价为卷积</strong>：前面提到的用W矩阵去进行通道维度的排列实际上就是对原有的数据在通道维度上进行线性组合，生成和输入均为c个通道。同channel用一个字母表示，把输入看做$A=(a_1,a_2,a_3)^T$，输出看做$B=(b_1,b_2,b_3)^T$，则变换为$$B = WA$$<br>注意思考一下W应该是<strong>左乘A</strong>，仔细举例思考一下，讲的时候可以写出来，Then：</p>
<p>方法二：如果直接对这$h\times w \times c$的向量（记作h）以W为卷积核进行卷积，W按行分块记为$(w_1,w_2,w_3)^T$，则输出的第一层feature map则为$w_1$卷积核对三通道做卷积得到的结果，想一下卷积的过程，他的时间复杂度为$O(h\times w\times c^2)$<br>【注意：注意这里应该是计算<strong>求雅各比行列式时的复杂度</strong>，等效前即为，等效为卷积之后，变换的行列式即为卷积操作求偏导后的行列式，求偏导前卷积的计算时间复杂度为缩小的】<br>对卷积操作求雅各比行列式的时候，是对W求雅各比行列式再乘上了$h\times w$，最后再除以这个系数即可</p>
<p>注意 法二并没有降低时间复杂度！！！待整理</p>
</li>
<li><p>实际的实现方式-方法三：在法二的基础上进一步分解矩阵，能够进一步降低时间复杂度<br>（其实这是PLU分解？？！）<a target="_blank" rel="noopener" href="https://www.qiujiawei.com/linear-algebra-3/">参考</a><br>不明白的：P是干啥的，为啥一定要有P<br>注意：L对角线均为1 U的对角线均为0，所以才有$diag(s)$，方便后面计算雅各比行列式<br>P的作用就是增加稳定性，没有其它的作用，可以看上面参考文章中举的例子</p>
</li>
<li><p>训练时的操作：随机采样一个矩阵，P可以根据规则计算出来然后固定，随后进行分解，只优化剩余参数</p>
</li>
</ol>
<h3 id="1-2-3-仿射耦合层"><a href="#1-2-3-仿射耦合层" class="headerlink" title="1.2.3 仿射耦合层"></a>1.2.3 仿射耦合层</h3><ol>
<li>拆分&amp;仿射相加的变换：好说，主要关注其余细节</li>
<li>初始化：分块后由上到下的映射函数NN使用0初始化，初始映射为恒等映射（算是一个小技巧，有助于训练很深的网络）<br>看实验部分可知，每个NN设置了3个卷积层，第二个隐藏层具有relu，通道为512，卷积核大小1x1，第一个和最后一个卷积核大小为3x3</li>
<li>分割与链接：在channel维度上，仅在此维度上（虽然RealNVP测试了其他分割方式）</li>
<li>排列：使用1x1卷积</li>
</ol>
<h3 id="1-2-4-多尺度结构"><a href="#1-2-4-多尺度结构" class="headerlink" title="1.2.4 多尺度结构"></a>1.2.4 多尺度结构</h3><ol>
<li>回去看Real NVP~，关于多尺度的理解可以看<a target="_blank" rel="noopener" href="https://blog.csdn.net/hacker_long/article/details/100138464">这一篇博客</a>，不止流模型，其他深度模型也经常用浅层特征和深层特征结合，比如SSD</li>
<li>基本的squeeze操作以改变维度，每一次都会增加通道的数量，每一个尺度会保持一定时间，在当前尺度上会有几个模块化操作拼接成小整体进行</li>
<li>要注意的是多尺度层有一半直接对应隐变量的操作，那么先验分布如何取的？那个博客中z因此并非正态分布的说法对不对？【待看源码！！！】</li>
</ol>
<h2 id="1-3-定量实验"><a href="#1-3-定量实验" class="headerlink" title="1.3 定量实验"></a>1.3 定量实验</h2><ol>
<li>NN层设置：将上文</li>
<li>测试1x1卷积的功能：选用了另外两种与其对比<br>测试加性耦合层和放射耦合层的特性</li>
<li>衡量生成模型的一个指标：bits per dimension（BPD），参考<a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/423120/%EF%BC%8Cwhat-is-bits-per-dimension-bits-dim-exactly-in-pixel-cnn-papers">BPD介绍1</a>，<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1705.07057.pdf">另一篇2018的flow中详细说了这个概念</a><br>在deepmind一篇回顾包含glow在内的深度生成模型的文章中，提到了几个评价指标：对数似然函数（越高越好）和 BPD（bits-per-dimension，越低越好）<br>嘤，外国社区讲的还是好清楚：<br>通常计算负对数似然的时候，对softmax的，通常取的是自然对数ln（雀食，前面提负对数似然的时候一直没有说以什么为底，这里负对数似然就是作为loss，详见背景回顾的一般流模型框架），这时候需要将<strong>负</strong>对数似然再除以log2换底为以2为底的，再除以通道数<br>为什么要这样呢？负对数似然不是表示信息嘛，把他转换成2为底的就是单位为bit，除以通道数就可以了。注意与对数似然不同多了个负号~</li>
</ol>
<h2 id="1-4-定性实验"><a href="#1-4-定性实验" class="headerlink" title="1.4 定性实验"></a>1.4 定性实验</h2><ol>
<li>考虑高分辨率数据集，256x256大小，minibatch大小为1</li>
<li>采样：从低温模型中采样会产生更高质量的样本？？？是为啥？？？原文引用了<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05751">ICML上的一篇文章</a>，这篇文章又引用了<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1702.00783">另一篇文章。。</a></li>
<li>这个应该是在查看图片效果的时候，以一定的规律从隐空间中进行采样，然后直接映射到x查看输出，和训练无关。<strong>线索指向了贪婪解码</strong>【原来主要资料在NLP的生成。。。】，应该就是调节采样格律的分布后从中依概率进行采样（而非贪婪采样），结合glow中讲的来看就清楚一点了。【待从源码看一眼】</li>
<li>好像不用看源码也能理解？！结合SRFlow的操作，就是对采样的高斯分布的方差用温度进行了代替，原理：</li>
<li>其余部分：关注以下操纵隐空间变量的方法即可，求解出了代表微笑的隐空间向量~</li>
</ol>
<h1 id="2-SRFlow-Learning-the-Super-Resolution-Space-with-Normalizing-Flow"><a href="#2-SRFlow-Learning-the-Super-Resolution-Space-with-Normalizing-Flow" class="headerlink" title="2. SRFlow: Learning the Super-Resolution Space with Normalizing Flow"></a>2. SRFlow: Learning the Super-Resolution Space with Normalizing Flow</h1><p>之后几篇应用都以glow模型提出的几种基本层作为起点，重点加深理解一下flow的训练过程，以及搞明白conditional怎么添加的</p>
<h2 id="2-1-Model"><a href="#2-1-Model" class="headerlink" title="2.1 Model"></a>2.1 Model</h2><h3 id="2-1-1-Conditional-Affine-Coupling"><a href="#2-1-1-Conditional-Affine-Coupling" class="headerlink" title="2.1.1 Conditional Affine Coupling"></a>2.1.1 Conditional Affine Coupling</h3><ol>
<li>添加condition之一：将LR图像添加到了每一个flow块中的每一个耦合层上</li>
<li>在2.1.1和2.1.2开始前，都需要对低分辨率图像进行编码$u=g_\theta (x)$，非可逆网络。<br>编码方式为基于RRDB的CNN网络对低分图像进行处理，将5个RRDB块输出的64个channel维特征进行拼接得到320个channel的特征。<br>注意这个RRDB网络可以用于SR，或者说本来就能用于SR因此才选用其进行特征提取，训练时先训练此网络，以L1loss为目标，带上采样/解码层，使用的时候丢弃解码层只保留编码模块来用。</li>
<li>条件耦合层：仿射耦合层上，过非可逆网络获取scale和bias的时候同时将u作为输入</li>
<li>具体实现：将u通过网络resize到$h_A$的维度上（空间维度一样），resize的方法见2.1.2（文章讲顺序的挺奇怪的，正文和附录不是一个顺序），然后按通道拼接即可</li>
</ol>
<h3 id="2-1-2-Affine-Injector"><a href="#2-1-2-Affine-Injector" class="headerlink" title="2.1.2 Affine Injector"></a>2.1.2 Affine Injector</h3><ol>
<li>目的：以上方法只是在一半添加了condition，使用逐元素注入特征的方法进一步添加SR的信息</li>
<li>方法：对编码u进行非可逆网络的变换以逐元素对当前特征进行操作</li>
<li>插入：怪不得这一层和上一层都喜欢对网络变换后的scale进行取e指数的操作，原来是算对数似然的时候算雅各比好算！</li>
<li>网络结构：第一层conv_Relu：降维到64个channel，随后第二层conv_relu：64-&gt;64，随后两个独立的卷积层处理分别得到scale和bias</li>
</ol>
<h3 id="2-1-3-多尺度架构"><a href="#2-1-3-多尺度架构" class="headerlink" title="2.1.3 多尺度架构"></a>2.1.3 多尺度架构</h3><ol>
<li>伴随squeeze而产生，注意看一下有无中图抛弃的隐变量？有，每一个split代表丢弃了50%的隐空间，将其直接对应到了高斯分布中</li>
<li>每次squeeze会使一个通道上图片的长宽变为一半，通道数变为四倍，详见Fig10</li>
<li>为了防止棋盘格效应，每次squeeze之后的前几个模块不添加条件层和仿射层</li>
<li>split：剔除50%的隐空间向量</li>
</ol>
<h2 id="2-2-实验"><a href="#2-2-实验" class="headerlink" title="2.2 实验"></a>2.2 实验</h2><ol>
<li>提到了temperature！！！而且是直接修改了正态分布的方差，这和glow里提到的一样，为什么可以这样呢？？？怎么将p(x)的修改等效为z的方差的改变呢？</li>
</ol>
<p>补充 做ppt时发现一个写的比较好的<a target="_blank" rel="noopener" href="https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html#vae--flows">网站</a><br>以及，很多内容在做PPT的时候理解有不同，见ppt讲稿</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/Journal-Club/" rel="tag"># Journal Club</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/01/26/2021%E7%BE%8E%E8%B5%9BA%E9%A2%98O%E5%A5%96%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" rel="prev" title="2021美赛A题O奖论文阅读笔记">
      <i class="fa fa-chevron-left"></i> 2021美赛A题O奖论文阅读笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/02/02/Neural-networks-to-learn-protein-sequence-function-relationships-from-deep-mutational-scanning-data/" rel="next" title="(2020 PNAS) Neural networks to learn protein sequence-function relationships from deep mutational scanning data">
      (2020 PNAS) Neural networks to learn protein sequence-function relationships from deep mutational scanning data <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-%E5%BC%95%E8%A8%80"><span class="nav-text">0. 引言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-GLOW%EF%BC%9AGlow-Generative-Flow-with-Invertible-1%C3%971-Convolutions"><span class="nav-text">1. GLOW：Glow: Generative Flow with Invertible 1×1 Convolutions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E6%B5%81%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-%E8%83%8C%E6%99%AF"><span class="nav-text">1.1 流生成模型简介-背景</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-1-%E8%B4%9F%E5%AF%B9%E6%95%B0%E4%BC%BC%E7%84%B6%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-text">1.1.1 负对数似然优化目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-2-%E6%B5%81%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6"><span class="nav-text">1.1.2 流生成模型基本框架</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-GLOW%E6%A1%86%E6%9E%B6"><span class="nav-text">1.2 GLOW框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-0-%E4%BB%8E%E4%B8%A4%E4%B8%AA%E8%A7%92%E5%BA%A6%E5%8E%BB%E7%90%86%E8%A7%A3%EF%BC%9A%E5%8D%95%E4%B8%AAflow%E5%B1%82%E5%86%85%E6%AF%8F%E4%B8%80%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%9C%E7%94%A8-%E6%95%B4%E4%BD%93%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%A1%86%E6%9E%B6"><span class="nav-text">1.2.0 从两个角度去理解：单个flow层内每一模块的作用+整体的多尺度框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-%E5%8F%AF%E9%80%861x1%E5%8D%B7%E7%A7%AF"><span class="nav-text">1.2.2 可逆1x1卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-3-%E4%BB%BF%E5%B0%84%E8%80%A6%E5%90%88%E5%B1%82"><span class="nav-text">1.2.3 仿射耦合层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-4-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%BB%93%E6%9E%84"><span class="nav-text">1.2.4 多尺度结构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-%E5%AE%9A%E9%87%8F%E5%AE%9E%E9%AA%8C"><span class="nav-text">1.3 定量实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-%E5%AE%9A%E6%80%A7%E5%AE%9E%E9%AA%8C"><span class="nav-text">1.4 定性实验</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-SRFlow-Learning-the-Super-Resolution-Space-with-Normalizing-Flow"><span class="nav-text">2. SRFlow: Learning the Super-Resolution Space with Normalizing Flow</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Model"><span class="nav-text">2.1 Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-Conditional-Affine-Coupling"><span class="nav-text">2.1.1 Conditional Affine Coupling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-Affine-Injector"><span class="nav-text">2.1.2 Affine Injector</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-3-%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%9E%B6%E6%9E%84"><span class="nav-text">2.1.3 多尺度架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E5%AE%9E%E9%AA%8C"><span class="nav-text">2.2 实验</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Setsuna F"
      src="/images/Setsuna.gif">
  <p class="site-author-name" itemprop="name">Setsuna F</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=30798036&auto=1&height=66"></iframe>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Setsuna F</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : '6CgVCOtkzLbk3u7IRxE0uPD2-gzGzoHsz',
      appKey     : 'YgbVRNOpg4sfjHgXNAB43zvN',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
